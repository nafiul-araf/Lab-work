# -*- coding: utf-8 -*-
"""my_association_custom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fy20H0jnpF7Wkq5Pa1Zdv48_3BU_umwM
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mlxtend.frequent_patterns import apriori,association_rules

# %matplotlib inline
sns.set(rc={
    'figure.figsize':(20, 15)
})


data=pd.read_csv("Copy of Depression and Happiness Factor Analysis.csv")

data=data.drop(['Timestamp','How much have you succeeded to cope up with the environment of your educational institution?','How long did you sleep last night?(in hours)',
                'Age','Unnamed: 20'],axis='columns')

data.rename({'Relationship status':'Relationship_status','Are you satisfied with your meal today?':'Satisfaction_with_meal','Which year are you in?':'Year',
             'How are you feeling right now?':'Felling_right_now','Your location ?':'Location','Are you happy with your financial state?':'Happy_with_financial',
             'Understanding with your family members?':'Understanding_with_family','Are you feeling pressure in your study or work right now?':'Study_pressure',
             'Are you satisfied with your academic result?':'Satisfaction_academic_result','Are you happy with your living place?':'Living_place_happiness',
             'Who supports you when you are not succeeding in your academic life?':'Supports_in_academic_life',
             'Have you used any social media within the last 6 hours?':'Using_social_media','Do you have inferiority complex?':'Inferiority_complex',
             'Are you feeling sick/health issues today?':'Sick_or_not_today','Have you done any recreational activity (sports, gaming, hobby etc.) today?':'Recreational_activity',
             'On a scale of 1-100, how would you express this feeling?':'Express_feeling'},axis=1,inplace=True)

def apriori_association_rules(df,column):
    """This function analyse the unique element of each features which have more than one unique value or element and found the association rules with the feelings level 
    (Very Good, Good, Normal, Bad, Very Bad). It splits the data according to the each unique values of the features. One Hot encoding are used to encode the data. Then it builds 
    the model and analyses the result.
    
    Input:
         df: The entire pandas dataframe.
         column: The target feature. One feature at a time.
    
    Output:
         un_val: A list of unique values/items of the given features.
         basket_list: A list of splitting data according to the each unique values of the features. The data is a pandas dataframe for each item.
         basket_list_encoded: A list of encoded data of the splitting data.
         apriori_rules_list: A list of tuple of the resultant association rules shape (rows, columns). Rows are the total founded rules.
         plot: Visualization of founded association rules for each unique items. It returns a seaborn's heatmap for each of the items.
    """
    
    un_val=list(df[column].unique())
    #return un_val
    
    basket_list=[]
    for i in un_val:
        basket_i = (df[df[column] == i] 
          .groupby(['Year', 'Felling_right_now'])['Express_feeling'] 
          .sum().unstack().reset_index().fillna(0) 
          .set_index('Year'))
        basket_list.append(basket_i)
    #return un_val, basket_list
    
    
    basket_list_encoded=[]
    def hot_encode(x): 
        if(x<= 0): 
            return 0
        if(x>= 1): 
            return 1
    for i in basket_list:
        basket_encode = i.applymap(hot_encode)
        basket_list_encoded.append(basket_encode)
    #return un_val, basket_list, basket_list_encoded
    
    apriori_rules_list=[]
    for i in basket_list_encoded:
        frq_items = apriori(i, min_support = 0.05, use_colnames = True)
        apriori_rules = association_rules(frq_items, metric ="lift", min_threshold = 1) 
        apriori_rules = apriori_rules.sort_values(['confidence', 'lift'], ascending =[False, False])
        apriori_rules = apriori_rules.shape
        apriori_rules_list.append(apriori_rules)
    #return un_val, basket_list, basket_list_encoded, apriori_rules_list
    
    apriori_rules_df=[]
    for i in basket_list_encoded:
        frq_items = apriori(i, min_support = 0.05, use_colnames = True)
        apriori_rules = association_rules(frq_items, metric ="lift", min_threshold = 1) 
        apriori_rules = apriori_rules.sort_values(['confidence', 'lift'], ascending =[False, False])
        apriori_rules_df.append(apriori_rules)
    #return un_val, basket_list, basket_list_encoded, apriori_rules_list
    
    
    for i in apriori_rules_df:
        i['lhs_items']=i['antecedents'].apply(lambda x:len(x) )
        i[i['lhs_items']>1].sort_values('lift',ascending=False).head()
        i['antecedents_']=i['antecedents'].apply(lambda a: ','.join(list(a)))
        i['consequents_']=i['consequents'].apply(lambda a: ','.join(list(a)))
        pivot=i[i['lhs_items']>1].pivot(index='antecedents_',columns='consequents_',values='lift')
        b=sns.heatmap(pivot,annot=True,annot_kws={"size": 16})
        b.set_xlabel("consequents_",fontsize=30)
        b.set_ylabel("antecedents_",fontsize=30)
        plt.yticks(rotation=0)
        plt.xticks(rotation=90)
        plt.show()
    
    return un_val, basket_list, basket_list_encoded, apriori_rules_list
